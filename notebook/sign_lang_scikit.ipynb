{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3acf7c7b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fe8515d8e0eb388ce79930ea7b6c63cb",
     "grade": false,
     "grade_id": "cell-14bdc41e163110b6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Sign Language Dataset Scikit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6d9c67",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "340354f8bc0f0c53961e7f6762bd47e8",
     "grade": false,
     "grade_id": "cell-51db7564f748aef7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The Sign Language Dataset consists of 9680 grayscale images of hand signs for the digits 0-9 and the alphabets a-z. Thus, this is a multiclass classification problem with 36 classes. Your task is to build a machine learning model that can accurately classify images from this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185aef08",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dfd3766dc129d20a384b6fe374f898ba",
     "grade": false,
     "grade_id": "cell-e4af33c6fde73887",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Loading the dataset\n",
    "\n",
    "You **do not** need to upload any data. Both the visible training dataset and the hidden test dataset are already available on the Jupyter hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab3f5dfd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ef93277d6faf4a26d52b648647386063",
     "grade": false,
     "grade_id": "cell-8c7257ef51480021",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /var/folders/9l/hc6vjb_16sj0br4xnxqpwcxw0000gn/T/matplotlib-bchtu_po because the default path (/Users/thomas/.matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f58be18",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2a20016a3ec4e174980204fdb21a3c57",
     "grade": false,
     "grade_id": "cell-636bfe55501bec94",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Setting the path of the training dataset (that was already provided to you)\n",
    "\n",
    "running_local = True if os.getenv('JUPYTERHUB_USER') is None else False\n",
    "DATASET_PATH = \".\"\n",
    "\n",
    "# Set the location of the dataset\n",
    "if running_local:\n",
    "    # If running on your local machine, the sign_lang_train folder's path should be specified here\n",
    "    local_path = \"sign_lang_train\"\n",
    "    if os.path.exists(local_path):\n",
    "        DATASET_PATH = local_path\n",
    "else:\n",
    "    # If running on the Jupyter hub, this data folder is already available\n",
    "    # You DO NOT need to upload the data!\n",
    "    DATASET_PATH = \"/data/mlproject21/sign_lang_train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b27e849",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "80e80b0135d964a577c59224e58423d4",
     "grade": false,
     "grade_id": "cell-8532dde78b48d38e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Utility function\n",
    "\n",
    "def read_csv(csv_file):\n",
    "    with open(csv_file, newline='') as f:\n",
    "        reader = csv.reader(f)\n",
    "        data = list(reader)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1e80e6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bc0334c0cfa0645319a201d00563c638",
     "grade": false,
     "grade_id": "cell-f6ce53d70b7a4b20",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Data Loading using PyTorch\n",
    "\n",
    "For creating and training your model, you can work with any machine learning library of your choice. \n",
    "\n",
    "If you choose to work with [PyTorch](https://pytorch.org/), you will need to create your own [Dataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) class for loading the data. This is provided below. See [here](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html) for a nice example of how to create a custom data loading pipeline in PyTorch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b4a9e4e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b92fa8c2a2c39e1bcfc5d5f36bfdc0a2",
     "grade": false,
     "grade_id": "cell-0e305bc0958e0408",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms, utils, io\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from string import ascii_lowercase\n",
    "\n",
    "\n",
    "class SignLangDataset(Dataset):\n",
    "    \"\"\"Sign language dataset\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, class_index_map=None, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.data = read_csv(os.path.join(root_dir, csv_file))\n",
    "        self.root_dir = root_dir\n",
    "        self.class_index_map = class_index_map\n",
    "        self.transform = transform\n",
    "        # List of class names in order\n",
    "        self.class_names = list(map(str, list(range(10)))) + list(ascii_lowercase)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Calculates the length of the dataset-\n",
    "        \"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns one sample (dict consisting of an image and its label)\n",
    "        \"\"\"\n",
    "\n",
    "        # Read the image and labels\n",
    "        image_path = os.path.join(self.root_dir, self.data[idx][1])\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        # Shape of the image should be H,W,C where C=1\n",
    "        image = np.expand_dims(image, 0)\n",
    "        # The label is the index of the class name in the list ['0','1',...,'9','a','b',...'z']\n",
    "        # because we should have integer labels in the range 0-35 (for 36 classes)\n",
    "        label = self.class_names.index(self.data[idx][0])\n",
    "\n",
    "        sample = {'image': image, 'label': label}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58a7659",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f03a81c186cc5531728e6c012d0efd57",
     "grade": false,
     "grade_id": "cell-a177a28ccf1ee8bb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Implementations\n",
    "\n",
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "dataset = SignLangDataset(csv_file=\"labels.csv\", root_dir=DATASET_PATH)\n",
    "\n",
    "TRAINING_DATA_LENGTH = int(len(dataset) * 0.8)\n",
    "TESTING_DATA_LENGTH = len(dataset) - TRAINING_DATA_LENGTH\n",
    "training_data, testing_data = random_split(dataset, [TRAINING_DATA_LENGTH, TESTING_DATA_LENGTH])\n",
    "\n",
    "def get_data_labels(dataset):\n",
    "    data = list()\n",
    "    labels = list()\n",
    "\n",
    "    for item in dataset:\n",
    "        data.append(item['image'])\n",
    "        labels.append(item['label'])\n",
    "\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "X, Y = get_data_labels(training_data)\n",
    "X = X.reshape(TRAINING_DATA_LENGTH, -1)\n",
    "\n",
    "X_test, Y_test = get_data_labels(testing_data)\n",
    "X_test = X_test.reshape(TESTING_DATA_LENGTH, -1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decision Tree"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "DecisionTreeClassifier()"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(criterion='gini')\n",
    "\n",
    "clf.fit(X, Y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data: 1.0\n",
      "Testing Data: 0.39359504132231404\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Data:\", clf.score(X, Y))\n",
    "print(\"Testing Data:\", clf.score(X_test, Y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/thomas/Documents/Thomas/Uni/4_Semester/ML/sign_language/venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": "LogisticRegression(verbose=True)"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X, Y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data: 0.9939307851239669\n",
      "Testing Data: 0.7143595041322314\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Data:\", log_reg.score(X, Y))\n",
    "print(\"Testing Data:\", log_reg.score(X_test, Y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ANN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.75490898\n",
      "Iteration 2, loss = 1.69653389\n",
      "Iteration 3, loss = 1.29076086\n",
      "Iteration 4, loss = 1.04849732\n",
      "Iteration 5, loss = 0.89835993\n",
      "Iteration 6, loss = 0.80091519\n",
      "Iteration 7, loss = 0.71164187\n",
      "Iteration 8, loss = 0.63526531\n",
      "Iteration 9, loss = 0.56954650\n",
      "Iteration 10, loss = 0.52567082\n",
      "Iteration 11, loss = 0.48694625\n",
      "Iteration 12, loss = 0.43616984\n",
      "Iteration 13, loss = 0.40795641\n",
      "Iteration 14, loss = 0.37649022\n",
      "Iteration 15, loss = 0.35593887\n",
      "Iteration 16, loss = 0.31807238\n",
      "Iteration 17, loss = 0.29158045\n",
      "Iteration 18, loss = 0.28239361\n",
      "Iteration 19, loss = 0.25512628\n",
      "Iteration 20, loss = 0.23507059\n",
      "Iteration 21, loss = 0.21750258\n",
      "Iteration 22, loss = 0.20767019\n",
      "Iteration 23, loss = 0.19350298\n",
      "Iteration 24, loss = 0.19390384\n",
      "Iteration 25, loss = 0.16553587\n",
      "Iteration 26, loss = 0.14776921\n",
      "Iteration 27, loss = 0.14419917\n",
      "Iteration 28, loss = 0.13015751\n",
      "Iteration 29, loss = 0.12612691\n",
      "Iteration 30, loss = 0.12022650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomas/Documents/Thomas/Uni/4_Semester/ML/sign_language/venv/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "MLPClassifier(max_iter=30, random_state=1, verbose=True)"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(100,), verbose=True, random_state=1, max_iter=30)\n",
    "X_norm = X / 255\n",
    "clf.fit(X_norm, Y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data: 0.9855371900826446\n",
      "Testing Data: 0.8037190082644629\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Data:\", clf.score(X, Y))\n",
    "print(\"Testing Data:\", clf.score(X_test, Y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}